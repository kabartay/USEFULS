{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_kw = dict(bins=60, normed=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "* Check if folding scheme can improve the quality\n",
    "* Compare 2-3-..-10 schemes. Does quality become better while a number of folds grows?\n",
    "* Plot rocs for all models, plot depedence nfolds vs AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "data = pandas.read_csv('datasets/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables = list(set(data.columns) - {'id', 'min_ANNmuon', 'mass', 'signal', 'production', 'SPDhits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide train on train, test\n",
    "train_index, test_index = train_test_split(range(len(data)))\n",
    "train = data.iloc[train_index, :]\n",
    "test = data.iloc[test_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoldingClassifier in sklearn-style from rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rep.metaml import FoldingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "base_gb = GradientBoostingClassifier(max_depth=6, learning_rate=0.01, n_estimators=200, \n",
    "                                     min_samples_leaf=50, max_features=8, subsample=0.7)\n",
    "folding_example = FoldingClassifier(base_gb, features=variables, n_folds=3)\n",
    "folding_example.fit(train, train.signal.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train folding schemes for different number of folds\n",
    "from collections import OrderedDict\n",
    "\n",
    "# dictionary of models, should contain all your models\n",
    "folding_all = OrderedDict()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare roc curves for  the training sample (folding predicts data fold by that classifier which was trained without this fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot roc curve for all models\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot dependence between number of folds and AUC\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same for the test sample (folding takes an average of all classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** In this case we don't need to split into train-test, and can train on the whole data because of folding scheme!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending \n",
    "(hierarchy training using the source of the $\\tau\\to\\mu\\mu\\mu$ decay)\n",
    "\n",
    "Check on different models if this hierarchy training over a model works better than the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### blending training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide train into two stage for hierarchy training\n",
    "train_index1, train_index2 = train_test_split(range(len(train)))\n",
    "train1 = train.iloc[train_index1, :]\n",
    "train2 = train.iloc[train_index2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data for each tau source\n",
    "production_data = []\n",
    "bck = train1[train1.signal == 0]\n",
    "productions = {1, 2, 4, 5, 6}\n",
    "for production in productions:\n",
    "    production_data.append(train1[(train1.signal == 1) & (train1.production == production)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train models for each tau source\n",
    "\n",
    "# add trained model for each tau to the `models`\n",
    "models = []\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict second stage data and test data by all models \n",
    "# add new predictions-features to the variables\n",
    "variables_blending = variables[:]\n",
    "for index, model in enumerate(models):\n",
    "    train2['new_{}'.format(index)] = model.predict_proba(train2[variables])[:, 1]\n",
    "    test['new_{}'.format(index)] = model.predict_proba(test[variables])[:, 1]\n",
    "    variables_blending.append('new_{}'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train resulting model using old features and new features\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare ROCs for two schemes\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute AUC for both schemes\n",
    "print 'Blending', roc_auc_score(test.signal.values, blending_probs)\n",
    "print 'Simple', roc_auc_score(test.signal.values, simple_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "Do you get the significant improvement? Conduct the same experiment for another model of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate blending classifier's output to probabilities \n",
    "\n",
    "* Platt regression (logistic regression)\n",
    "* isotonic regression (monotonic function, optimizes $\\sum w_i (y_i - \\hat{y}_i)^2$)\n",
    "\n",
    "Nice comment about the output calibration using two methods http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide test into two parts: \n",
    "#    the first to calibrate output of the classifer,\n",
    "#    the second test the quality of the calibration\n",
    "test_index1, test_index2 = train_test_split(range(len(test)))\n",
    "test1 = test.iloc[test_index1, :]\n",
    "test2 = test.iloc[test_index2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isotonic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "iso_calib = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blending_probs = ... # predictions for the test sample by blending classifier\n",
    "iso_probs = iso_calib.predict(blending_probs[test_index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####compare histograms for the calibrated output and the initial output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare isotonic calibrated probabilities and estimated probabilities using bins\n",
    "* Plot isotonic calibrated output for [0, 1]\n",
    "* Divide output into several bins, for each bin compute $s_i / (s_i + b_i)$ - estimated probability in bin to be a signal event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_probs(temp_probs, name, bins_cal=20):\n",
    "    bins = linspace(0, 1, bins_cal)\n",
    "    bins_center = bins[:-1] + (bins[1:] - bins[:-1]) / 2.\n",
    "    bins_index = numpy.searchsorted(bins[1:-1], temp_probs)\n",
    "    sig_probs = numpy.bincount(bins_index, weights=test2.signal.values)\n",
    "    bck_probs = numpy.bincount(bins_index, weights=1-test2.signal.values)\n",
    "    plot(..., label=name)\n",
    "    plot([0, 1], [0, 1], label='ideal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_probs(blending_probs[test_index2], 'standard')\n",
    "plot(..., label='iso calibrated')\n",
    "legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platt regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import logit\n",
    "platt_calib = ...\n",
    "# transform output from [0, 1] to [-infty, infty] to train Logistic Regression, because of its loss function expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "platt_probs = platt_calib.predict_proba(logit(blending_probs[test_index2]).reshape(-1, 1))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####compare histograms for the calibrated output and the initial output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Platt calibrated probabilities and estimated probabilities using bins\n",
    "* Plot Platt calibrated output for [0, 1]\n",
    "* Divide output into several bins, for each bin compute $s_i / (s_i + b_i)$ - estimated probability in bin to be a signal event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_probs(blending_probs[test_index2], 'standard')\n",
    "plot(..., label='platt calibrated')\n",
    "legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute AUC, logloss, MSE for initial and calibrated values. How do metrics vary after the calibration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "\n",
    "def compute_metrics_for_calibration(probs_initial, probs, name):\n",
    "    print 'Initial', 'AUC:', roc_auc_score(test2.signal, probs_initial)\n",
    "    print 'Initial', 'Log loss:', log_loss(test2.signal, probs_initial)\n",
    "    print 'Initial', 'MSE:', mean_squared_error(test2.signal, probs_initial)\n",
    "    print name, 'AUC:', roc_auc_score(test2.signal, probs)\n",
    "    print name, 'Log loss:', log_loss(test2.signal, probs)\n",
    "    print name, 'MSE:', mean_squared_error(test2.signal, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for isotonic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_metrics_for_calibration(blending_probs[test_index2], iso_probs, 'Isotonic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for Platt method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_metrics_for_calibration(blending_probs[test_index2], platt_probs, 'Platt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log loss and MSE become lower (better), and AUC also become lower (worse) (for the Platt AUC will the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hypotheses metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train any model on training data and compare different metrics on the test data:\n",
    "\n",
    "* $\\frac{s} {\\sqrt{(s + b)}}$\n",
    "* $\\frac{s} {\\sqrt{(10 + b)}}$\n",
    "* $\\frac{s} {\\sqrt{(0.1 + b)}}$\n",
    "* $\\frac{s} {(2.5 + \\sqrt{b})}$ - Punzi metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#U-test\n",
    "\n",
    "Use U-test to compare different ND pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_agreement = pandas.read_csv('datasets/check_agreement.csv')\n",
    "data_MC = pandas.concat([data_agreement[data_agreement.signal == 1], data[data.signal == 1]])\n",
    "data_MC['signal'] = numpy.array([0] * sum(data_agreement.signal.values == 1) + [1] * sum(data.signal.values == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agreement_features = ['LifeTime', 'VertexChi2', 'DOCAtwo']\n",
    "disagreement_features = ['dira', 'IP', 'IPSig', 'IP_p0p2', 'IP_p1p2', 'isolationb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Divide train on train, test\n",
    "train_MC_index, test_MC_index = train_test_split(range(len(data_MC)))\n",
    "train_MC = data_MC.iloc[train_MC_index, :]\n",
    "test_MC = data_MC.iloc[test_MC_index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code the U-statistic and compute number of sigmas: $\\frac{U - \\mathbb{E}U}{\\sqrt{\\mathbb{V}U}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def u_test_compute(labels, probs):\n",
    "    # should return number of sigmas\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the calssifier to distinguish two ND pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on the agreement features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on the disagreement features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute AUC and U-test sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### What we can say about the similarity of two ND pdfs for both examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
