{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reweighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hep_ml.reweight** contains methods to reweight distributions: `BinsReweighter`, `GBReweighter`\n",
    "\n",
    "**hep_ml.metrics_utils** contains `ks_2samp_weighted`. Use it to compute KS metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hep_ml import reweight\n",
    "import root_numpy\n",
    "import pandas\n",
    "from hep_ml.metrics_utils import ks_2samp_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storage = 'https://github.com/arogozhnikov/hep_ml/blob/data/data_to_download/'\n",
    "!wget -O datasets/MC_distribution.root -nc $storage/MC_distribution.root?raw=true\n",
    "!wget -O datasets/RD_distribution.root -nc $storage/RD_distribution.root?raw=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "Pay attention that here we work with `.root` files and `root_numpy` can help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['hSPD', 'pt_b', 'pt_phi', 'vchi2_b']\n",
    "\n",
    "original = root_numpy.root2array('datasets/MC_distribution.root', branches=columns)\n",
    "target = root_numpy.root2array('datasets/RD_distribution.root', branches=columns)\n",
    "\n",
    "original = pandas.DataFrame(original)\n",
    "target = pandas.DataFrame(target)\n",
    "\n",
    "original_weights = numpy.ones(len(original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_kw = {'bins': 100, 'normed': True, 'alpha': 0.5}\n",
    "\n",
    "def plot_pdf(features, new_original_weights, weights_target=None, label=''):\n",
    "    figsize(14, 8)\n",
    "    if weights_target is None:\n",
    "        weights_target = numpy.ones(len(target), dtype=float)\n",
    "    for index, column in enumerate(features, 1):\n",
    "        xlim = numpy.percentile(target[column], [0.01, 99.99])\n",
    "        subplot(2, 2, index)\n",
    "        hist(original[column].values, weights=new_original_weights, range=xlim, \n",
    "             label=label + 'original(MC)', **hist_kw)\n",
    "        hist(target[column].values, range=xlim, label='target(real)', **hist_kw)\n",
    "        title(column)\n",
    "        legend()\n",
    "        print column, 'KS:', ks_2samp_weighted(original[column], target[column], \n",
    "                                               weights1=new_original_weights, \n",
    "                                               weights2=weights_target)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_pdf(columns, original_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare 1D reweighting: Bin, GB. \n",
    "\n",
    "* Choose one variable for reweighting\n",
    "* Use KS metric to compare which method is the best.\n",
    "* Do other variables after 1D reweigthig agree? What does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_1d = ...\n",
    "# play with it\n",
    "bins_reweighter = reweight.BinsReweighter(...)\n",
    "bins_reweighter.fit(original[variable_1d], target[variable_1d])\n",
    "\n",
    "bins_weights = bins_reweighter.predict_weights(original[variable_1d])\n",
    "plot_pdf(columns, bins_weights, label='Bin 1D: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see for some of other variables KS metric became a bit worse, for some - a bit better. The Difference is inessential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "* Compute CvM between chosen feature and others. Are they correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import compute_cvm\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a random variable the correlation is 10 times less than for features thus all features are correlated indeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GB reweighting\n",
    "\n",
    "This algorithm is inspired by gradient boosting and is able to fight curse of dimensionality.\n",
    "It uses decision trees and special loss functiion (**ReweightLossFunction**).\n",
    "\n",
    "**GBReweighter** supports negative weights (to reweight MC to splotted real data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reweighter = reweight.GBReweighter(...)\n",
    "reweighter.fit(original[variable_1d], target[variable_1d])\n",
    "\n",
    "gb_weights = reweighter.predict_weights(original[variable_1d])\n",
    "plot_pdf(columns, gb_weights, label='GB 1D: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare ND reweighting: Bin, GB. \n",
    "\n",
    "Use ML to compare which method is the best. Does it really work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin ND reweighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GB ND reweighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GB-discrimination\n",
    "let's check how well the classifier is able to distinguish these distributions. ROC AUC is taken as measure of quality.\n",
    "\n",
    "For this puprose we split data into train and test, then train a classifier to distinguish these distributions.\n",
    "If ROC AUC = 0.5 on test, distibutions are equal, if ROC AUC = 1.0, they are ideally separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = numpy.concatenate([original, target])\n",
    "labels = numpy.array([0] * len(original) + [1] * len(target))\n",
    "\n",
    "weights = {}\n",
    "weights['original'] = original_weights\n",
    "weights['bins'] = bins_weights\n",
    "weights['gb_weights'] = gb_weights\n",
    "\n",
    "\n",
    "for name, new_weights in weights.items():\n",
    "    W = numpy.concatenate([new_weights / new_weights.sum() * len(target), [1] * len(target)])\n",
    "    Xtr, Xts, Ytr, Yts, Wtr, Wts = train_test_split(data, labels, W, random_state=42, train_size=0.51)\n",
    "    clf = GradientBoostingClassifier(...).fit(Xtr, Ytr, sample_weight=Wtr)\n",
    "    \n",
    "    print name, roc_auc_score(Yts, clf.predict_proba(Xts)[:, 1], sample_weight=Wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus GB reweighter is better because its AUC is close to 0.5. And it strongly improves original pdf while Bin reweighter improves a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing some simple expressions:\n",
    "The most interesting is checking some other variables in multidimensional distributions (those are expressed via original variables).\n",
    "\n",
    "* Compute different expressions. For them compute KS.\n",
    "* Make the `hist2d` plots for one combination of features vs another combination of features\n",
    "\n",
    "**Hint**:\n",
    "`hist2d(original.eval(expression1).values, original.eval(expression2).values, \n",
    "        bins=100, normed=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_ks_of_expression(expression):\n",
    "    col_original = original.eval(expression, engine='python')\n",
    "    col_target = target.eval(expression, engine='python')\n",
    "    w_target = numpy.ones(len(col_target), dtype='float')\n",
    "    print 'No reweight   KS:', ks_2samp_weighted(col_original, col_target, weights1=original_weights, weights2=w_target)        \n",
    "    print 'Bins reweight KS:', ks_2samp_weighted(col_original, col_target, weights1=bins_weights, weights2=w_target)\n",
    "    print 'GB Reweight   KS:', ks_2samp_weighted(col_original, col_target, weights1=gb_weights, weights2=w_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check KS for simple expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_ks_of_expression('hSPD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_ks_of_expression('hSPD * pt_phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# yours expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hist2d plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hist2d_expressions(f1, f2, vmax):\n",
    "    figsize(15, 12)\n",
    "    \n",
    "    subplot(2, 2, 1)\n",
    "    hist2d(target.eval(f1).values, target.eval(f2).values, \n",
    "           bins=100, normed=True)\n",
    "    clim(0, vmax)\n",
    "    title('target: {} vs {}'.format(f1, f2), color='y')\n",
    "    \n",
    "    subplot(2, 2, 2)\n",
    "    hist2d(original.eval(f1).values, original.eval(f2).values, \n",
    "           bins=100, normed=True)\n",
    "    clim(0, vmax)\n",
    "    title('original: {} vs {}'.format(f1, f2), color='y')\n",
    "    xlim(min(target.eval(f1).values), max(target.eval(f1).values))\n",
    "    ylim(min(target.eval(f2).values), max(target.eval(f2).values))\n",
    "    \n",
    "    subplot(2, 2, 4)\n",
    "    hist2d(original.eval(f1).values, original.eval(f2).values, \n",
    "           bins=100, normed=True, \n",
    "           weights=bins_weights)\n",
    "    clim(0, vmax)\n",
    "    title('Bin RW: {} vs {}'.format(f1, f2), color='y')\n",
    "    xlim(min(target.eval(f1).values), max(target.eval(f1).values))\n",
    "    ylim(min(target.eval(f2).values), max(target.eval(f2).values))\n",
    "    \n",
    "    subplot(2, 2, 3)\n",
    "    hist2d(original.eval(f1).values, original.eval(f2).values, \n",
    "           bins=100, normed=True, \n",
    "           weights=gb_weights)\n",
    "    clim(0, vmax)\n",
    "    xlim(min(target.eval(f1).values), max(target.eval(f1).values))\n",
    "    ylim(min(target.eval(f2).values), max(target.eval(f2).values))\n",
    "    title('GB RW: {} vs {}'.format(f1, f2), color='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist2d_expressions('hSPD * pt_phi', 'vchi2_b', 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist2d_expressions('(pt_b * pt_phi) ** (0.1)', 'hSPD', 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist2d_expressions('pt_b **0.5', 'pt_phi ** 0.1', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist2d_expressions(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### What reweighter is better for feature combinations?\n",
    "\n",
    "As you can see, GB reweighter is better by its KS for expressions, also for hist2d it looks better and is more similar to the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build classifier, which agree on MC and real\n",
    "\n",
    "It is time to apply our knowledge to analyze $\\tau\\to3\\mu$ without only removing disagreement features!\n",
    "\n",
    "**TODO: **\n",
    "\n",
    "* analyze $\\tau\\to3\\mu$ data to build classifier which pass agreement threshold 0.09\n",
    "* compare models trained on disagreement features, without them, with reweigthing (Bin, GB)\n",
    "* compute AUC and don't forget use weights during the AUC computation if you reweighted data.\n",
    "* Does reweighting only by one feature `SPDhits` help to pass agreement threshold?\n",
    "* Compare MC signal vs MC control to avoid systematic error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('datasets/training.csv')\n",
    "data_agreement = pandas.read_csv('datasets/check_agreement.csv')\n",
    "train_features = list(set(data_agreement.columns) - {'id', 'signal', 'weight'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute KS for all features to find the most disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_mc_control = data_agreement[data_agreement.signal == 1]['weight']\n",
    "weights_rd_control = data_agreement[data_agreement.signal == 0]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_ks_for_all(features, weights):\n",
    "    ks_train_features = []\n",
    "    for feature in features:\n",
    "        pdf1 = data_agreement.loc[data_agreement.signal == 0, feature].values\n",
    "        pdf2 = data_agreement.loc[data_agreement.signal == 1, feature].values\n",
    "        ks_train_features.append(ks_2samp_weighted(pdf1, pdf2, weights1=weights_rd_control, weights2=weights))\n",
    "    return pandas.DataFrame({'Feature': features, 'KS': ks_train_features}).sort('KS')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_ks_for_all(train_features, weights_mc_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst features are `SPDhits`, `FlightDistance`, `IP_p1p2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide train on train, test\n",
    "train_index, test_index = train_test_split(range(len(data)))\n",
    "train = data.iloc[train_index, :]\n",
    "test = data.iloc[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to test model on ks and calculate quality\n",
    "def test_model(model, features, reweighter=None, reweight_features=None):\n",
    "    mc_weights = weights_mc_control\n",
    "    test_weights = numpy.ones(len(test))\n",
    "    if reweighter is not None:\n",
    "        mc_weights = reweighter.predict_weights(data_agreement.loc[data_agreement.signal == 1, reweight_features])\n",
    "        test_weights[test.signal.values == 1] = reweighter.predict_weights(\n",
    "            test.loc[test.signal == 1, reweight_features])\n",
    "    probs = model.predict_proba(data_agreement[features])[:, 1]\n",
    "    pdf1 = probs[data_agreement.signal.values == 0]\n",
    "    pdf2 = probs[data_agreement.signal.values == 1]\n",
    "    model_agr = ks_2samp_weighted(pdf1, pdf2, weights1=weights_rd_control, weights2=mc_weights)\n",
    "    print 'Agreement', model_agr, model_agr < 0.09\n",
    "    print 'AUC', roc_auc_score(test.signal.values, model.predict_proba(test[features])[:, 1], \n",
    "                               sample_weight=test_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GB training with or without reweighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_ks_between_mc(model, train_features, reweighter, reweight_features):\n",
    "    pdf1 = model.predict_proba(test.loc[test.signal == 1, train_features].values)[:, 1]\n",
    "    pdf2 = model.predict_proba(data_agreement.loc[data_agreement.signal == 1, train_features].values)[:, 1]\n",
    "    weights1 = numpy.ones(len(pdf1))\n",
    "    weights2 = numpy.ones(len(pdf2))\n",
    "    \n",
    "    if reweighter is not None:\n",
    "        weights1 = reweighter.predict_weights(test.loc[test.signal == 1, reweight_features].values)\n",
    "        weights2 = reweighter.predict_weights(data_agreement.loc[data_agreement.signal == 1, reweight_features].values)\n",
    "\n",
    "    print 'MC vs MC KS:', ks_2samp_weighted(pdf1, pdf2, weights1=weights1, weights2=weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_gb(train_features, reweighter=None, reweight_features=None):\n",
    "    # define the model GB or another if you want\n",
    "    gb = ...\n",
    "    weights = numpy.ones(len(train))\n",
    "    if reweighter is not None:\n",
    "        weights[train.signal.values == 1] = reweighter.predict_weights(train.loc[train.signal == 1, reweight_features])\n",
    "    gb.fit(train[train_features], train['signal'].values, sample_weight=weights)\n",
    "    test_model(gb, train_features, reweighter, reweight_features)\n",
    "    compute_ks_between_mc(gb, train_features, reweighter, reweight_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple model on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gb(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove disagree features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features_agree = list(set(train_features) - {...})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gb(train_features_agree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweighters for several features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define target and original pdfs for reweighters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data_agreement[data_agreement.signal == 0]\n",
    "original = data_agreement[data_agreement.signal == 1]\n",
    "reweight_features = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin Reweighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_reweighter = reweight.BinsReweighter(...)\n",
    "bins_reweighter.fit(original[reweight_features], target[reweight_features], target_weight=weights_rd_control)\n",
    "bins_weights = bins_reweighter.predict_weights(original[reweight_features])\n",
    "plot_pdf(reweight_features, bins_weights, label='tau BIN ND: ', weights_target=weights_rd_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_ks_for_all(train_features, bins_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gb(train_features, bins_reweighter, reweight_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB Reweighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do the same as for bin reweighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_ks_for_all(train_features, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gb(train_features, reweighter, reweight_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweight only on `SPDhits` (example of reweighting which doesn't help to pass agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reweight_features = ['SPDhits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reweighter = reweight.GBReweighter(n_estimators=100, learning_rate=0.3, max_depth=5, min_samples_leaf=500, \n",
    "                                   gb_args={'subsample': 0.6})\n",
    "reweighter.fit(original[reweight_features], target[reweight_features], target_weight=weights_rd_control)\n",
    "gb_weights = reweighter.predict_weights(original[reweight_features])\n",
    "plot_pdf(reweight_features, gb_weights, label='tau GB ND: ', weights_target=weights_rd_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_ks_for_all(train_features, gb_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gb(train_features, reweighter, reweight_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try apply iterative learning scheme on $\\tau\\to3\\mu$. Does it help to improve quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables_1 = ['isolationa', 'isolationb', 'isolationc', 'SPDhits', 'p0_track_Chi2Dof',\n",
    "              'p1_track_Chi2Dof', 'p2_track_Chi2Dof', 'p0_pt', 'p1_pt', 'p2_pt', 'p0_eta', 'p1_eta', 'p2_eta',\n",
    "              'p0_IPSig', 'p1_IPSig', 'p2_IPSig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables_2 = list(set(train.columns) - {'mass', 'signal', 'production', 'min_ANNmuon'} - set(variables_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=400, max_depth=7, \n",
    "                                learning_rate=0.01, min_samples_leaf=50, subsample=0.7, \n",
    "                                max_features=8)\n",
    "gb.fit(train[variables_2], train['signal'].values)\n",
    "test_model(gb, variables_2)\n",
    "compute_ks_between_mc(gb, variables_2, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
