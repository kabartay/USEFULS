{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Theano\n",
    "\n",
    "Theano is a python library and an optimizing compiler, which allows to define, optimize and compute mathematical expressions effectively using multidimensional arrays.\n",
    "\n",
    "Features:\n",
    "\n",
    "* integration with NumPy\n",
    "* effective computation of gradient (can automatically build expressions to compute gradient)\n",
    "* fast and stable optimization (can recognize numerical inaccurate expressions and compute them using more stable algorithms)\n",
    "* clear using GPU\n",
    "* dynamic C++ code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import \n",
    "* theano\n",
    "* theano.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import theano.tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic expessions for tensors\n",
    "Theanoâ€™s strength is in expressing symbolic calculations involving tensors. There are many types of symbolic expressions for tensors:\n",
    "\n",
    "* scalar\n",
    "* vector\n",
    "* matrix\n",
    "* tensor\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create two vectors and one scaler\n",
    "x = T.vector() \n",
    "y = T.vector()\n",
    "alpha = T.scalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute \n",
    "$x + \\alpha y + (\\sum x_i, ... ,\\sum x_i)^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define mathematical expression (you can use any function, which you use for NumPy arrays)\n",
    "z = x + alpha * y + T.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile defined expression\n",
    "`theano.function`\n",
    "\n",
    "Returns a callable object that will calculate outputs from inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input variables, output expessions\n",
    "compiled_expr = theano.function([x, y, alpha], z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute compiled expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_val = numpy.arange(10)\n",
    "y_val = numpy.arange(10)\n",
    "alpha_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45. ,  46.5,  48. ,  49.5,  51. ,  52.5,  54. ,  55.5,  57. ,  58.5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_expr(x_val, y_val, alpha_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "* compute $(<x, \\alpha y> + <\\beta x, y>)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create two vectors and one scaler\n",
    "x = T.vector() \n",
    "y = T.vector()\n",
    "alpha = T.scalar()\n",
    "beta = T.scalar()\n",
    "compiled_expr = theano.function([x, y, alpha, beta], \n",
    "                        (T.sum(x * (alpha * y)) + T.sum(y * (beta * x))) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12996.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = numpy.arange(10)\n",
    "y_val = numpy.arange(10)\n",
    "alpha_val = 0.1\n",
    "beta_val = 0.3\n",
    "compiled_expr(x_val, y_val, alpha_val, beta_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names for expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define \n",
    "x = T.vector(name='x') \n",
    "y = T.vector(name='y')\n",
    "alpha = T.scalar(name='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = alpha * x * T.log(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `theano.printing.pprint()`\n",
    "Theano provides the functions `theano.printing.pprint()` and `theano.printing.debugprint()` to print a graph to the terminal before or after compilation. `pprint()` is more compact and math-like, `debugprint()` is more verbose. Theano also provides `pydotprint()` that creates an image of the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((a * x) * log(y))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.pprint(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compiled_expr = theano.function(inputs=[x, y, alpha], outputs=[z], name='function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{Composite{(log(i0) * i1 * i2)}} [@A] ''   1\n",
      " |y [@B]\n",
      " |InplaceDimShuffle{x} [@C] ''   0\n",
      " | |a [@D]\n",
      " |x [@E]\n"
     ]
    }
   ],
   "source": [
    "theano.printing.debugprint(compiled_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file is available at graph.png\n"
     ]
    }
   ],
   "source": [
    "theano.printing.pydotprint(compiled_expr, outfile=\"graph.png\", var_with_name_simple=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grad` returns symbolic gradients for one or more variables with respect to some cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.scalar(name='x') \n",
    "func = T.log(x) * T.sinh(x)\n",
    "func_prime = T.grad(func, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(((fill((log(x) * sinh(x)), TensorConstant{1.0}) * sinh(x)) / x) + ((fill((log(x) * sinh(x)), TensorConstant{1.0}) * log(x)) * cosh(x)))'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.pprint(func_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check yourself that this expession indeed gradient!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func_prime_function = theano.function([x], func_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x107160310>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSJEmSJEmSJEmSqsv/A03pldgRhhHHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107163890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = numpy.linspace(0.1, 2, 100)\n",
    "plot([func_prime_function(point) for point in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.vector(name='x') \n",
    "func = T.sum(x * x)\n",
    "func_prime = T.grad(func, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((fill((x * x), fill(Sum{acc_dtype=float64}((x * x)), TensorConstant{1.0})) * x) + (fill((x * x), fill(Sum{acc_dtype=float64}((x * x)), TensorConstant{1.0})) * x))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.pprint(func_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func_prime_function = theano.function([x], func_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.2,  0.2]),\n",
       " array([ 0.62222222,  0.62222222]),\n",
       " array([ 1.04444444,  1.04444444]),\n",
       " array([ 1.46666667,  1.46666667]),\n",
       " array([ 1.88888889,  1.88888889]),\n",
       " array([ 2.31111111,  2.31111111]),\n",
       " array([ 2.73333333,  2.73333333]),\n",
       " array([ 3.15555556,  3.15555556]),\n",
       " array([ 3.57777778,  3.57777778]),\n",
       " array([ 4.,  4.])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = numpy.linspace(0.1, 2, 10)\n",
    "x2 = numpy.linspace(0.1, 2, 10)\n",
    "[func_prime_function(numpy.array([point1, point2])) for point1, point2 in zip(x1, x2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check yourself that this result is correct!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared variables\n",
    "`theano.shared` returns a SharedVariable variable, initialized with a copy or reference of `value`.\n",
    "\n",
    "Variable with Storage that is shared between functions that it appears in. These variables are meant to be created by registered shared constructors (see `shared_constructor()`).\n",
    "The user-friendly constructor is `shared()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = theano.shared(numpy.arange(10, dtype=float), name='weight')\n",
    "x = T.vector('x')\n",
    "func = theano.function([x], T.sum(x * w))\n",
    "func_grad = theano.function([x], T.grad(T.sum(x * w), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_grad(numpy.arange(10) * 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.vector('x')\n",
    "A = T.matrix('A')\n",
    "z = A.dot(x)\n",
    "normAx = theano.function([x, A], z.dot(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute this expression by yourself:\n",
    "\n",
    "$A = [[1, 1], [1, 1]]$\n",
    "\n",
    "$x = [0, 2]^T$\n",
    "\n",
    "What is the answer?\n",
    "\n",
    "Now compare it with theano result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normAx([0, 2], [[1, 1], [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_grad = theano.function([x, A], T.grad(z.dot(z), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute gradient by yourself!!! Write its expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(w, x) | grad(x) = w$\n",
    "\n",
    "$(Ax, Ax) | grad(x) = 2 (A^T A) x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute gradient for \n",
    "$A = [[0, 1], [1, 1]]$\n",
    "\n",
    "**in point**:\n",
    "$x = [1, 1]^T$\n",
    "\n",
    "What is the answer?\n",
    "\n",
    "Now compute the same with theano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  4.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_grad([0, 1], [[1, 1], [1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression \n",
    "\n",
    "Write logistic regression algorithm using theano! Now this is really very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import function to create toy dataset for classification\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = 10 # number of features\n",
    "centers = 2 # number of classes\n",
    "X, y = make_blobs(n_samples=10000, centers=centers, n_features=n_features)\n",
    "X, X_test, y, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create theano objects for data(they should be shared because we know X, y)\n",
    "X_ = theano.shared(X, name='X')\n",
    "y_ = theano.shared(y, name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define vector of weights, we don't know it, that is why:\n",
    "w = T.vector(name='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression description:\n",
    "$p_i = sigmoid(\\sum_j X_{ij}w_j)$\n",
    "\n",
    "$loss=\\sum y_i \\log{p} + (1-y_i)\\log{(1 - p)}$\n",
    "\n",
    "$-loss \\to min$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write expression for probabilities\n",
    "p_sig = T.nnet.sigmoid(X_.dot(w))\n",
    "p_bck = 1 - p_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write expression for loss\n",
    "llh_ = y_.dot(T.log(p_sig)) + (1 - y_).dot(T.log(p_bck))\n",
    "minus_llh_ = - llh_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile loss expression, compile gradient expression for loss\n",
    "loss_function = theano.function([w], minus_llh_)\n",
    "loss_grad = theano.function([w], theano.grad(minus_llh_, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(50823.57239060069)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(numpy.random.random(n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have expessions for loss and it gradient and we need some method of optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# minimize loss function using its gradient\n",
    "result = minimize(fun=loss_function, x0=numpy.zeros(n_features), jac=loss_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   status: 0\n",
       "  success: True\n",
       "     njev: 5\n",
       "     nfev: 5\n",
       " hess_inv: array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
       "      fun: -0.0\n",
       "        x: array([-362.83230601,  -67.433171  , -221.33906513, -565.37415879,\n",
       "       -139.89050158,  395.38166795,  222.71447739, -376.76992602,\n",
       "        280.57181274, -449.54250183])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "      jac: array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
       "      nit: 1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_optimal = result['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now predict output of logistic regression for the test sample and compute AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = X_test.dot(w_optimal)\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Is it simple with theano?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another implementation of logistic regression (add shift and l2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_steps = 1000\n",
    "X_ = T.matrix(\"x\")\n",
    "y_ = T.vector(\"y\")\n",
    "w = theano.shared(numpy.random.random(X.shape[1]), name=\"w\")\n",
    "# Add shift to the model\n",
    "b = theano.shared(0., name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_sig = T.nnet.sigmoid(T.dot(X_, w) - b) \n",
    "llh_ = y_ * T.log(p_sig) + (1 - y_) * T.log(1 - p_sig)\n",
    "minus_llh_ = - llh_\n",
    "cost = minus_llh_.mean() + 0.01*(w**2).sum() # add l2 regularization with parameter 0.01 / The cost to optimize\n",
    "grad_w, grad_b = T.grad(cost, [w, b])\n",
    "# define updates after run the function\n",
    "train = theano.function(inputs=[X_, y_], outputs=[p_sig, minus_llh_], \n",
    "                        updates=[[w, w - 0.001*grad_w], [b, b - 0.001*grad_b]], name = \"train\")\n",
    "predict = theano.function(inputs=[X_], outputs=p_sig, name = \"predict\")\n",
    "\n",
    "for i in range(training_steps):\n",
    "    probs, err = train(X, y)\n",
    "pred = predict(X_test)\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-hidden layer\n",
    "This is a simple NN description with one hidden layer:\n",
    "\n",
    "Params: \n",
    "\n",
    "* W,\n",
    "\n",
    "* v\n",
    "\n",
    "Calculations:\n",
    "\n",
    "* h = sigmoid(X_.dot(W))\n",
    "* output = v.dot(h)\n",
    "* p_sig = sigmoid(output)\n",
    "* p_bck = 1 - p_sig\n",
    "\n",
    "\n",
    "Code it using theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden = 10\n",
    "\n",
    "X_ = theano.shared(X, name='X')\n",
    "y_ = theano.shared(y, name='y')\n",
    "param = T.vector()\n",
    "\n",
    "# we have one vector with all weights, and from it we need to extract matrix and vector\n",
    "W_ = param[:n_features * n_hidden].reshape((n_features, n_hidden))\n",
    "v_ = param[n_features * n_hidden:]\n",
    "\n",
    "h = T.nnet.sigmoid(X_.dot(W_))\n",
    "output = h.dot(v_)\n",
    "p_sig = T.nnet.sigmoid(output)\n",
    "p_bck = 1 - p_sig\n",
    "llh_ = y_.dot(T.log(p_sig)) + (1 - y_).dot(T.log(p_bck))\n",
    "minus_llh_ = -llh_\n",
    "\n",
    "loss_function = theano.function([param], minus_llh_)\n",
    "loss_grad = theano.function([param], theano.grad(minus_llh_, param))\n",
    "result = minimize(loss_function, \n",
    "                  numpy.random.random(n_features*n_hidden + n_hidden), \n",
    "                  jac=loss_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform result into matrix and vector\n",
    "optimal = result['x']\n",
    "W = optimal[:n_features * n_hidden].reshape(n_features, n_hidden)\n",
    "v = optimal[n_features * n_hidden:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = expit(X_test.dot(W))\n",
    "pred = pred.dot(v)\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.88951992,  8.7154808 , -1.33103596, ...,  7.84275691,\n",
       "        -1.71435118,  3.21358125],\n",
       "       [ 0.7906828 ,  6.80442128, -6.28298061, ..., -2.96493226,\n",
       "         4.78836884, -6.26725524],\n",
       "       [ 7.26258108,  6.11155358, -1.3987088 , ...,  5.97295578,\n",
       "        -0.42921152,  2.53363283],\n",
       "       ..., \n",
       "       [ 0.46598312,  4.62155534, -6.73518731, ..., -1.21393881,\n",
       "         5.02606149, -6.69344647],\n",
       "       [ 0.38682719,  4.97253328, -4.81810229, ..., -1.67211168,\n",
       "         5.54852303, -8.79102878],\n",
       "       [ 1.09640089,  6.56048096, -4.89995423, ...,  0.47006076,\n",
       "         6.14387727, -8.20203142]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 1-hidden layer NN write 2-layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate another dataset\n",
    "X, y = make_moons(n_samples=20000)\n",
    "X, X_test, y, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10775a3d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neu8dzlUUQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107946e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(X[:, 0], X[:, 1], c=y, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ = theano.shared(X, name='X')\n",
    "y_ = theano.shared(y, name='y')\n",
    "param = T.vector()\n",
    "\n",
    "n_hidden_1 = 10\n",
    "n_hidden_2 = 6\n",
    "n_features = X.shape[1]\n",
    "\n",
    "n_1 = n_features * n_hidden_1\n",
    "n_2 = n_hidden_1 * n_hidden_2\n",
    "\n",
    "W1_ = param[:n_1].reshape((n_features, n_hidden_1))\n",
    "W2_ = param[n_1: n_1 + n_2].reshape((n_hidden_1, n_hidden_2))\n",
    "v_ = param[n_1 + n_2:]\n",
    "\n",
    "h1 = T.nnet.sigmoid(X_.dot(W1_))\n",
    "h2 = T.nnet.sigmoid(h1.dot(W2_))\n",
    "output = h2.dot(v_)\n",
    "\n",
    "p_sig = T.nnet.sigmoid(output)\n",
    "p_bck = 1 - p_sig\n",
    "llh_ = y_.dot(T.log(p_sig)) + (1 - y_).dot(T.log(p_bck))\n",
    "minus_llh_ = -llh_\n",
    "\n",
    "loss_function = theano.function([param], minus_llh_)\n",
    "loss_grad = theano.function([param], theano.grad(minus_llh_, param))\n",
    "result = minimize(loss_function, numpy.random.normal(size=n_1 + n_2 + n_hidden_2), jac=loss_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimal = result['x']\n",
    "W1 = optimal[:n_1].reshape(n_features, n_hidden_1)\n",
    "W2 = optimal[n_1:n_1 + n_2].reshape(n_hidden_1, n_hidden_2)\n",
    "v = optimal[n_1 + n_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = expit(X_test.dot(W1))\n",
    "pred = expit(pred.dot(W2))\n",
    "pred = pred.dot(v) \n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function fo NN to modify it by a simple way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_predict_NN(X, y, X_test, activate_functions, output_function, hidden_layers):\n",
    "    X_ = theano.shared(X, name='X')\n",
    "    y_ = theano.shared(y, name='y')\n",
    "    param = T.vector()\n",
    "    dim = X.shape[1]\n",
    "    \n",
    "    def activation(data_, parameter):\n",
    "        n_previous = 0\n",
    "        dim_previous = dim\n",
    "        h = data_\n",
    "        for n_hidden, func in zip(hidden_layers, activate_functions):\n",
    "            N = dim_previous * n_hidden\n",
    "            W_ = parameter[n_previous:n_previous + N].reshape((dim_previous, n_hidden))\n",
    "            h = func(h.dot(W_))\n",
    "            dim_previous = n_hidden\n",
    "            n_previous += N\n",
    "\n",
    "        # output     \n",
    "        v_ = parameter[n_previous:]\n",
    "        output = h.dot(v_)\n",
    "        n_previous = n_previous + dim_previous\n",
    "        \n",
    "        return output_function(output), n_previous\n",
    "\n",
    "    p_sig = activation(X_, param)[0]\n",
    "    p_bck = 1 - p_sig\n",
    "    llh_ = y_.dot(T.log(p_sig)) + (1 - y_).dot(T.log(p_bck))\n",
    "    minus_llh_ = -llh_\n",
    "    \n",
    "    # optimize\n",
    "    loss_function = theano.function([param], minus_llh_)\n",
    "    loss_grad = theano.function([param], theano.grad(minus_llh_, param))\n",
    "    result = minimize(loss_function, numpy.random.normal(size=activation(X_, param)[1]), jac=loss_grad)\n",
    "    optimal_params = result['x']\n",
    "    \n",
    "    # predict data\n",
    "    data = T.matrix()\n",
    "    compiled_activation = theano.function([data, param], activation(data, param)[0])\n",
    "    \n",
    "    return compiled_activation(X_test, optimal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91160544065108384"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate another dataset\n",
    "X, y = make_moons(n_samples=1000)\n",
    "# add noise to data\n",
    "X += numpy.random.random(size=X.shape[0] * X.shape[1]).reshape(X.shape)\n",
    "X, X_test, y, y_test = train_test_split(X, y, train_size=0.5)\n",
    "\n",
    "pred = fit_predict_NN(X, y, X_test, [T.nnet.sigmoid] * 3, T.nnet.sigmoid, [20, 10, 5])\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activation intermediate functions:\n",
    "* sigmoid (which we used)\n",
    "* relu \n",
    "* softplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU - rectifier linear unit.\n",
    "\n",
    "In the context of artificial neural networks, the rectifier is an activation function defined as\n",
    "\n",
    "$f(x) = \\max(0, x)$\n",
    "\n",
    "where x is the input to a neuron. This activation function has been argued to be more biologically plausible than the widely used logistic sigmoid (which is inspired by probability theory; see logistic regression) and its more practical counterpart, the hyperbolic tangent. The rectifier is the most popular activation function for deep neural networks.\n",
    "\n",
    "A unit employing the rectifier is also called a rectified linear unit (ReLU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Softplus\n",
    "A smooth approximation to the rectifier is the analytic function\n",
    "\n",
    "$f(x) = \\ln(1 + e^x)$\n",
    "\n",
    "which is called the softplus function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_relu(alpha):\n",
    "    def relu(x):\n",
    "        return T.switch(x > 0, x, alpha * x)\n",
    "    return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate another dataset\n",
    "X, y = make_moons(n_samples=1000)\n",
    "X += numpy.random.random(size=X.shape[0] * X.shape[1]).reshape(X.shape)\n",
    "X, X_test, y, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87848001796138309"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = fit_predict_NN(X, y, X_test, [T.nnet.softplus] * 3, T.nnet.sigmoid, [10, 10, 5])\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92821059721598576"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = fit_predict_NN(X, y, X_test, [generate_relu(0.5)] * 2, T.nnet.sigmoid, [10, 10])\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclassification  Problem\n",
    "\n",
    "In this case we need use `softmax` activate fucntion for the last layer\n",
    "\n",
    "**TODO**:\n",
    "\n",
    "* Write multiclassification NN\n",
    "* add shift to the NN formula ( h = (x, w) + b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_predict_mult_NN(X, y, X_test, activate_functions, hidden_layers):\n",
    "    X_ = theano.shared(X, name='X')\n",
    "    y_ = theano.shared(y, name='y')\n",
    "    param = T.vector()\n",
    "    n_class = len(numpy.unique(y))\n",
    "    dim = X.shape[1]\n",
    "    \n",
    "    def activation(data_, parameter):\n",
    "        n_previous = 0\n",
    "        dim_previous = dim\n",
    "        h = data_\n",
    "        for n_hidden, func in zip(hidden_layers, activate_functions):\n",
    "            N = dim_previous * n_hidden\n",
    "            W_ = parameter[n_previous:n_previous + N].reshape((dim_previous, n_hidden))\n",
    "            n_previous += N\n",
    "            b = parameter[n_previous: n_previous + n_hidden]\n",
    "            n_previous += n_hidden\n",
    "            h = func(h.dot(W_) + 0. * b[numpy.newaxis, :]) # here is brodcasing for b => it will be copied for each row\n",
    "            dim_previous = n_hidden\n",
    "\n",
    "        # output     \n",
    "        v_ = parameter[n_previous:].reshape((dim_previous, n_class))\n",
    "        output = h.dot(v_)\n",
    "        n_previous = n_previous + dim_previous * n_class\n",
    "        \n",
    "        return T.nnet.softmax(output), n_previous\n",
    "    \n",
    "    p_ = activation(X_, param)[0]\n",
    "    llh_ = T.log(p_[T.arange(len(X)), y_]).sum()\n",
    "    minus_llh_ = -llh_\n",
    "    \n",
    "    # optimize\n",
    "    loss_function = theano.function([param], minus_llh_)\n",
    "    loss_grad = theano.function([param], theano.grad(minus_llh_, param))\n",
    "    result = minimize(loss_function, numpy.random.normal(size=activation(X_, param)[1]), \n",
    "                      jac=loss_grad)\n",
    "    optimal_params = result['x']\n",
    "    \n",
    "    data = T.matrix()\n",
    "    compiled_activation = theano.function([data, param], activation(data, param)[0])\n",
    "\n",
    "    return compiled_activation(X_test, optimal_params)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = 20\n",
    "n_class = 5\n",
    "X, y = make_blobs(n_samples=2000, centers=n_class, n_features=n_features)\n",
    "X += (numpy.random.normal(size=X.shape[0]*X.shape[1]) * 10).reshape(X.shape)\n",
    "X, X_test, y, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1090437d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a29f350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a28ced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "for func in [T.nnet.sigmoid, T.nnet.softmax, generate_relu(0.5)]:\n",
    "    pred = fit_predict_mult_NN(X, y, X_test, [], [])\n",
    "    imshow(confusion_matrix(y_test, numpy.argmax(pred, axis=1)), interpolation='nearest')\n",
    "    plt.xticks(range(n_class), range(n_class))\n",
    "    plt.yticks(range(n_class), range(n_class))\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net interafce in `hep_ml`: just write activation function using `theano`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hep_ml\n",
    "from hep_ml import nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hep_ml.nnet import AbstractNeuralNetworkClassifier\n",
    "\n",
    "class SimpleNeuralNetwork(AbstractNeuralNetworkClassifier):\n",
    "    def prepare(self):\n",
    "        # getting number of layers in input, hidden, output layers\n",
    "        # note that we support only one hidden layer here\n",
    "        n1, n2, n3 = self.layers_\n",
    "        \n",
    "        # creating parameters of neural network\n",
    "        W1 = self._create_matrix_parameter('W1', n1, n2)\n",
    "        W2 = self._create_matrix_parameter('W2', n2, n3)\n",
    "        \n",
    "        # defining activation function\n",
    "        def activation(input):\n",
    "            first = T.nnet.sigmoid(T.dot(input, W1))\n",
    "            return T.dot(first, W2)\n",
    "\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=2000)\n",
    "X += numpy.random.random(size=X.shape[0] * X.shape[1]).reshape(X.shape)\n",
    "X, X_test, y, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931114365278\n"
     ]
    }
   ],
   "source": [
    "nnet_simple = SimpleNeuralNetwork()\n",
    "nnet_simple.fit(X, y)\n",
    "pred = nnet_simple.predict_proba(X_test)[:, 1]\n",
    "print roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite above binary classification NN into this interace \n",
    "\n",
    "Here is you daon't need to add `b` parameter, this interface does it and includes additional column in `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyNeuralNetwork(AbstractNeuralNetworkClassifier):\n",
    "    def prepare(self):\n",
    "        # getting number of layers in input, hidden, output layers\n",
    "        # note that we support only one hidden layer here\n",
    "        W = []\n",
    "        # creating parameters of neural network\n",
    "        for index, n_cur in enumerate(self.layers_[1:]):\n",
    "            W.append(self._create_matrix_parameter('W{}'.format(index+1), self.layers_[index], n_cur))\n",
    "        \n",
    "        # defining activation function\n",
    "        def activation(input):\n",
    "            data = input\n",
    "            for W_matrix in W:\n",
    "                data = T.nnet.sigmoid(T.dot(data, W_matrix))\n",
    "            return data\n",
    "\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924218599962\n"
     ]
    }
   ],
   "source": [
    "nnet_my = MyNeuralNetwork(layers=[10, 5, 5])\n",
    "nnet_my.fit(X, y)\n",
    "pred = nnet_my.predict_proba(X_test)[:, 1]\n",
    "print roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your ideas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN in `hep_ml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hep_ml.nnet import PairwiseNeuralNetwork, RBFNeuralNetwork, MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931114365278\n",
      "0.945213974778\n",
      "0.916326579604\n"
     ]
    }
   ],
   "source": [
    "for models in [PairwiseNeuralNetwork(), RBFNeuralNetwork(), MLPClassifier()]:\n",
    "    models.fit(X, y)\n",
    "    pred = models.predict_proba(X_test)[:, 1]\n",
    "    print roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging over NN - meta algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959725689777\n"
     ]
    }
   ],
   "source": [
    "base = RBFNeuralNetwork()\n",
    "meta_ada = AdaBoostClassifier(base_estimator=base, n_estimators=10, learning_rate=0.05)\n",
    "meta_ada.fit(X, y)\n",
    "pred = meta_ada.predict_proba(X_test)[:, 1]\n",
    "print roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951771653543\n"
     ]
    }
   ],
   "source": [
    "base = RBFNeuralNetwork()\n",
    "meta_bagging = BaggingClassifier(base_estimator=base, n_estimators=50, max_samples=0.7)\n",
    "meta_bagging.fit(X, y)\n",
    "pred = meta_bagging.predict_proba(X_test)[:, 1]\n",
    "print roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oy! This can really work for simple data! Try apply this meta algorithms possibilities to your analysis and improve your models!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
