{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for histograms\n",
    "hist_kw = dict(bins=100, normed=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KS investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS metric pdf generation\n",
    "\n",
    "###TODO\n",
    "Build the KS-metric pdf by generating a pair of distributions from `numpy.random.random` many times and using `ks_2samp` function to compute KS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "n1 = 10000\n",
    "n2 = 20000\n",
    "\n",
    "# finish the function\n",
    "def generate_ks_pdf(n1, n2, points=30000):\n",
    "    ks = []\n",
    "    # for each point \n",
    "    for step in range(points):\n",
    "        # generate pdf1 and pdf2 from the same distributions\n",
    "        ...\n",
    "        # compute ks for generated pdfs\n",
    "        ks.append(...)\n",
    "    return numpy.array(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks_pdf = generate_ks_pdf(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(ks_pdf, **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption:\n",
    "\n",
    "KS metric pdf will be the same, no matter which distribution we used to generate samples.\n",
    "To be more precise, samples may be generated from any continuous distribution, not only uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the assumption!\n",
    "\n",
    "\n",
    "###TODO:\n",
    "* Generate two samples from a normal distribution and get KS metric pdf in this case. \n",
    "* Are two KS metric distributions similar (the first $PDF_{metric,u}$ is received by generating two samples from uniform pdf and the second $PDF_{metric,n}$ is received by generating two samples from normal pdf)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_ks_pdf_normal(n1, n2, points=30000):\n",
    "    ks = []\n",
    "    # for each point \n",
    "    for step in range(points):\n",
    "        # generate pdf1 and pdf2 from the same distributions\n",
    "        ...\n",
    "        # compute ks for generated pdfs\n",
    "        ks.append(...)\n",
    "    return numpy.array(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks_pdf_normal = generate_ks_pdf_normal(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(ks_pdf_normal, **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(ks_pdf, **hist_kw)\n",
    "hist(ks_pdf_normal, **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do you check these two KS metric distributions by eye? \n",
    "\n",
    "To check if $PDF_{metric,u}$ and $PDF_{metric,n}$ are similar compute KS metric between them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## How can one understand what this metric value means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two options here\n",
    "\n",
    "### 1. KS test:\n",
    "\n",
    "This is Kolmogorov-Smirnov statistic to test a hypothesis that two samples come from the same distibution.\n",
    "\n",
    "Statistic:\n",
    "\n",
    "$q= \\sqrt{\\frac{n*m}{n + m}}KS_{nm}$\n",
    "\n",
    "$K_{\\alpha} \\sim \\sqrt{-0.5 * \\ln{\\frac{1 - \\alpha}{2}}}$, \n",
    "\n",
    "where $\\alpha$ - statistical significance, $KS_{nm}$ - Kolmogorov-Smirnov metric.\n",
    "\n",
    "If $q > K_{\\alpha}$ then hypothesis (that both samples from the same distribution) will be rejected.\n",
    "\n",
    "### 2. P-value calculated using the KS metric pdf:\n",
    "\n",
    "You can calculate p-value using generated KS pdf to test the hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "Check that $PDF_{metric,u}$ and $PDF_{metric,n}$ come from the same distribution (It will mean that our assumption holds).\n",
    "\n",
    "Use the p-value returned by `ks_2samp` to understand KS-metric value between $PDF_{metric,u}$ and $PDF_{metric,n}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if p-value is not small we can't reject hypothesis (so consider them coming from the same distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ð¡an you now answer if the KS metric pdf depends on the initial continuous distribution, from which two samples are generated? Can you prove this behaviour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember how the KS metric is calculated using the roc curve you will understand that the KS metric use only the permutation of the sample1 in the sample2, $ks=\\max{|fpr - tpr|}$. Thus, the initial disribution will be transformed into a zeros-ones sequence, where zero means an element came from the sample1 and one - the sample2. If the samples were generated from the same distibution then probability of such zeros-ones sequence will be $\\frac{(n1 + n2)!}{n1!n2!}$ and it doesn't depend on the initial distribution. Thus, the initial distribution doesn't matter and we can generate the KS pdf using the uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###TODO:\n",
    "\n",
    "Above you checked the similarity of $PDF_{metric,u}$ and $PDF_{metric,n}$ using KS statistic. \n",
    "\n",
    "Now try option 2 to check this: generate KS metric distribution $PDF_{KS}$ for samples $PDF_{metric,u}$ and $PDF_{metric,n}$ and compute p-value of their distance using $PDF_{KS}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute p-value using the KS pdf \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** two p-values, obtained by two methods (KS statistic, KS metric distibution) are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two similar normal distributions are generated. By eye they are very similar, but the KS test says that hypothesis (the same distribution) should be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf1_g = numpy.random.normal(loc=10, scale=5, size=n1)\n",
    "pdf2_g = numpy.random.normal(loc=10.2, scale=5.3, size=n2)\n",
    "hist(pdf1_g, **hist_kw)\n",
    "hist(pdf2_g, **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ks_2samp(pdf1_g, pdf2_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpy.mean(ks_pdf > ks_2samp(pdf1_g, pdf2_g)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value < 0.005, thus the KS test says that samples were generated from different distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CvM investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mass and several predictions are generated to see the CvM metric:\n",
    "\n",
    "* mass from 1000 * exp(1), range=(0, 4000);\n",
    "* prediction_sin = sin(mass / 1000.)\n",
    "* prediction_rand = numpy.random.random\n",
    "* prediction_cut = zeros outside [1000, 1500] mass region and ones in this region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mass = 1000 * numpy.random.exponential(1, size=10000)\n",
    "mass = mass[mass < 4000]\n",
    "prediction_cut = numpy.zeros(len(mass))\n",
    "prediction_cut[(mass > 1000) & (mass < 1500)] = 1\n",
    "prediction_rand = numpy.random.random(len(mass))\n",
    "prediction_sin = numpy.sin(mass / 1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot:\n",
    "* mass histogram\n",
    "* mass histogram for each prediction selection > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(mass, **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(mass[prediction_cut > 0.5], **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(mass[prediction_rand > 0.5], **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(mass[prediction_sin > 0.5], **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For which prediction does selection change initial pdf? Check your thoughts using CvM metric.\n",
    "\n",
    "#### What predictions always must be uncorrelated with the mass? \n",
    "\n",
    "CvM metric can be calculated using:\n",
    "\n",
    "* `from utils import compute_cvm`\n",
    "* `compute_cvm(predictions, mass)`\n",
    "\n",
    "For CvM metric we haven't statistic like KS statistic to test hypothesis, that is why only pdf generation can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import compute_cvm\n",
    "# compute cvm for all predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate CvM metric distribution using appropriate distribution for predicitons generation.\n",
    "\n",
    "**Random predictions always are uncorellated with the mass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_cvm_pdf(mass, points=5000):\n",
    "    cvm = []\n",
    "    # for each point \n",
    "    for step in range(points):\n",
    "        # generate uncorellated predictions for mass\n",
    "        ...\n",
    "        # compute cvm for generated prediction and mass\n",
    "        cvm.append(...)\n",
    "    return numpy.array(cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvm_pdf = generate_cvm_pdf(mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(cvm_pdf, **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute p-value to check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers training:\n",
    "## check influence of the correlation restriction on the quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download \n",
    "\n",
    "* `training.csv`, \n",
    "* `check_correlation.csv`, \n",
    "\n",
    "to the folder `datasets/` from https://www.kaggle.com/c/flavours-of-physics/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('datasets/training.csv')\n",
    "data_correlation = pandas.read_csv('datasets/check_correlation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_correlation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = list(set(data_correlation.columns) - {'id'})\n",
    "train_features_wo_mass = list(set(data_correlation.columns) - {'id', 'mass'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(data[data.signal == 1]['mass'].values, label='signal MC', **hist_kw)\n",
    "hist(data[data.signal == 0]['mass'].values, label='bck real', **hist_kw)\n",
    "xlim(1600, 1950)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(data_correlation['mass'].values, label='correlation bck', **hist_kw)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "* Train any linear model and ensemble model on `train_features`.\n",
    "* Are models are correlated with the mass?\n",
    "* Compute the AUC for the models\n",
    "* Are they have essential difference?\n",
    "* Use feature `(mass - mass.mean())**2` instead of `mass`. How does it infuence on the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide train on train, test\n",
    "train_index, test_index = train_test_split(range(len(data)))\n",
    "train = data.iloc[train_index, :]\n",
    "test = data.iloc[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate cvm pdf\n",
    "tau_cvm = generate_cvm_pdf(data_correlation.mass.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(tau_cvm, **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to test model on cvm and calculate quality\n",
    "def test_model(model, features, cvm_pdf):\n",
    "    model_cvm = model.predict_proba(data_correlation[features])[:, 1]\n",
    "    model_corr = compute_cvm(data_correlation.mass.values, model_cvm)\n",
    "    print 'Correlation', model_corr, 'p-value', numpy.mean(cvm_pdf > model_corr)\n",
    "    print 'AUC', roc_auc_score(test.signal.values, model.predict_proba(test[features])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train ensemble\n",
    "# test on correlation and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train linear model\n",
    "# test on correlation and quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add new feature for linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['mean'] = (train.mass.values - train.mass.mean())**2\n",
    "test['mean'] = (test.mass.values - train.mass.mean())**2\n",
    "data_correlation['mean'] = (data_correlation.mass.values - train.mass.mean())**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(train[train.signal == 1]['mean'].values, label='signal MC', **hist_kw)\n",
    "hist(train[train.signal == 0]['mean'].values, label='bck real', **hist_kw)\n",
    "# xlim(1600, 1950)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train ensemble using new feature\n",
    "# test on correlation and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train linear using new feature\n",
    "# test on correlation and quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Result: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does shape of the mass in correlation dataset change depending on models' thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_shape(model, features):\n",
    "    probs = model.predict_proba(data_correlation[features])[:, 1]\n",
    "    hist_kw['bins'] = 30\n",
    "    for thr in [0.001, 0.05, 0.1, 0.5]:\n",
    "        hist(data_correlation[probs > thr]['mass'].values, label='thr=%1.2f' %thr, **hist_kw)\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_shape(..., train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the feature bagging and events bagging affect the CvM and quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the same ensemble using another max_features\n",
    "for max_features in [20, 15, 10, 5]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the same ensemble using another subsample\n",
    "for subsample in [0.2, 0.5, 0.9]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CvM and quality are both lower if max_feature/subsample becomes lower, but it is not sufficient to remove correlation. It will be useful, when you use feature (which is not strongly correlated with the mass) for training to prevent correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce new feature from mass to use it in training and make cvm much lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the competition cvm 0.002 threshold is set. Your model should pass it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer the question: \n",
    "* What quality can you get if `mass` is not used in the training? Is it different? Then why? \n",
    "* What model is better, linear or ensemble? Compare their cvm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train ensemble without mass\n",
    "# test on correlation and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train linear model without mass\n",
    "# test on correlation and quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=3)\n",
    "rf.fit(train[train_features_wo_mass], train['signal'].values)\n",
    "test_model(rf, train_features_wo_mass, tau_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain why this model is correlated with the mass, although mass feature is absent in training sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting possibilities:\n",
    "* overfitting-difference (difference between prediction's pdf for training and test datasets) - check by comparing distributions\n",
    "* overfitting-complexity (overfitting because too many estimators used in training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting-difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs_train = rf.predict_proba(train[train_features_wo_mass])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_kw['bins'] = 60\n",
    "hist_kw['alpha'] = 0.5\n",
    "hist_kw['range'] = (0, 1)\n",
    "hist(probs_train[train.signal.values == 1], color='r', label='train signal', **hist_kw)\n",
    "hist(probs[test.signal.values == 1], color='g', label='test signal', **hist_kw)\n",
    "legend(loc='upper center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(probs_train[train.signal.values == 0], color='b', label='train bck', **hist_kw)\n",
    "hist(probs[test.signal.values == 0], color='y', label='test bck', **hist_kw)\n",
    "legend(loc='upper center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus tree structure influences the correlation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature bagging invention\n",
    "\n",
    "Write your own feature bagging algorithm: features will be chosen with some probability.\n",
    "\n",
    "Compare using knn-method:\n",
    "\n",
    "* standard feature bagging and this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FeatureSampler(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # finish method: generate features proportionally their information \n",
    "        # compute information using roc auc score \n",
    "        # use numpy.choice to generate features indices\n",
    "        aucs = []\n",
    "        self.n_features = X.shape[1]\n",
    "        self.max_features = numpy.random.randint(2, high=8)\n",
    "        \n",
    "        for feature in range(self.n_features):\n",
    "            auc = ...\n",
    "            aucs.append(auc)\n",
    "        self.features_information = ...\n",
    "        self.used_features = ...\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # finish method returning necessary features         \n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_knn = KNeighborsClassifier(n_neighbors=50)\n",
    "pp_sampler = Pipeline([('sampler', FeatureSampler()), ('knn', simple_knn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train simple knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train knn with standard bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own feature bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does bagging improve knn algorithm? Does new feature sampler help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can some scaler help to improve knn quality?\n",
    "As an example, there is `sklearn.preprocessing.StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize:\n",
    "\n",
    "* Now you can understand the trade off between the corelation and quality\n",
    "* You can invent new algorithms which will be trained on the mass column and will be not correlated with the mass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
