{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_kw = dict(bins=60, normed=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KS investigation (with negative weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download \n",
    "\n",
    "* `check_agreement.csv`, \n",
    "\n",
    "to the folder `datasets/` from https://www.kaggle.com/c/flavours-of-physics/data\n",
    "\n",
    "It is a control channel, where 1-label corresponds to MC, 0-label - real data, `weight` - sPlot weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_agreement = pandas.read_csv('datasets/check_agreement.csv')\n",
    "features_for_ks = ['LifeTime', 'FlightDistance', 'IPSig', 'SPDhits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in features_for_ks:\n",
    "    hist(data_agreement[data_agreement.signal == 1][feature].values, label='MC', **hist_kw)\n",
    "    hist(data_agreement[data_agreement.signal == 0][feature].values, label='real', **hist_kw)\n",
    "    legend()\n",
    "    title(feature)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how sPlot weights change real data pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the same histograms with sPlot weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write KS for weights pdfs\n",
    "standard function doesn't support weights :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def compute_ks(pdf1, pdf2, weights1=None, weights2=None):\n",
    "    # Write KS metric between two weighted pdfs (see slides)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS metric pdf generation\n",
    "\n",
    "There are several things to know before doing it:\n",
    "\n",
    "* we cannot produce two samples from the same distribution with the weights, thus if we generate two samples from uniform and then compute weighted ks metric, obtained value will be greater than it is. That is why during testing hypothesis the probability of error type I will be greater than it is really (Our KS pdf will give the upper estimation of probability to reject H0, when it is true)\n",
    "\n",
    "* the second sample contains signal and background, which are sampled from different distributions.  \n",
    "In the second sample we need to generate not only signal (from the same distribution), but also bck from any distribution. But if we remember about sPlot weights property (they compensate bck) then we can conclude that generated bck could be compensated in sample using weights. Of course, some fluctuations can arise (maybe we should somehow estimate them)!\n",
    "\n",
    "* in the first approximation we can generate two samples as before\n",
    "\n",
    "###TODO\n",
    "\n",
    "* Check that for unweighted samples KS will be lower than for weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finish the function\n",
    "def generate_ks_pdf(n1, n2, w1=None, w2=None, points=3000):\n",
    "    ks = []\n",
    "    # for each point \n",
    "    for step in range(points):\n",
    "        # generate pdf1 and pdf2 from the same distributions\n",
    "        ...\n",
    "        # compute ks for generated pdfs\n",
    "        ...\n",
    "    return numpy.array(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n1 = numpy.sum(data_agreement.signal == 0)\n",
    "n2 = numpy.sum(data_agreement.signal == 1)\n",
    "w1 = data_agreement[data_agreement.signal == 0]['weight'].values\n",
    "w2 = data_agreement[data_agreement.signal == 1]['weight'].values\n",
    "ks_pdf = generate_ks_pdf(n1, n2)\n",
    "ks_pdf_weight = generate_ks_pdf(n1, n2, w1=w1, w2=w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist(ks_pdf, label='simple', **hist_kw)\n",
    "hist(ks_pdf_weight, label='weight', **hist_kw)\n",
    "legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###TODO:\n",
    "What features have least disagreement among `features_for_ks`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agreement restriction on the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How more disagreement features can influence the predictions agreement and classifier's quality?\n",
    "\n",
    "Do for this:\n",
    "\n",
    "* train any ensemble model on all features\n",
    "* remove `SPDhits` from training\n",
    "\n",
    "In the competition your ks metric should be less than **0.09**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('datasets/training.csv')\n",
    "train_features = list(set(data_agreement.columns) - {'id', 'signal', 'weight'})\n",
    "train_features_wo_spd = list(set(data_agreement.columns) - {'id', 'signal', 'weight', 'SPDhits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide train on train, test\n",
    "train_index, test_index = train_test_split(range(len(data)))\n",
    "train = data.iloc[train_index, :]\n",
    "test = data.iloc[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to test model on ks and calculate quality\n",
    "def test_model(model, features):\n",
    "    probs = model.predict_proba(data_agreement[features])[:, 1]\n",
    "    pdf1 = probs[data_agreement.signal.values == 0]\n",
    "    pdf2 = probs[data_agreement.signal.values == 1]\n",
    "    model_agr = compute_ks(pdf1, pdf2, weights1=w1, weights2=w2)\n",
    "    print 'Agreement', model_agr, model_agr < 0.09\n",
    "    print 'AUC', roc_auc_score(test.signal.values, model.predict_proba(test[features])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does subsample parameter influence the agreement and the quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does learning rate influence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of overfitting-complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=300, learning_rate=0.7, min_samples_leaf=50, subsample=0.5, \n",
    "                                max_features=20, max_depth=6)\n",
    "gb.fit(train[train_features_wo_spd], train['signal'].values)\n",
    "\n",
    "steps = []\n",
    "for probs in gb.staged_predict_proba(test[train_features_wo_spd]):\n",
    "    steps.append(roc_auc_score(test.signal.values, probs[:, 1]))\n",
    "steps_train = []\n",
    "for probs in gb.staged_predict_proba(train[train_features_wo_spd]):\n",
    "    steps_train.append(roc_auc_score(train.signal.values, probs[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(8, 6)\n",
    "plot(range(len(steps)), steps, label='test')\n",
    "plot(range(len(steps_train)), steps_train, label='train')\n",
    "legend(loc='best')\n",
    "ylabel('AUC')\n",
    "xlabel('n_esimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality on the train is increasing while the quality on the test is decreasing. This is really overfitting. We need take those number of iterations for which quality on test sample is qrowing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize:\n",
    "\n",
    "* The simple solution to improve an agreement is to remove too disagreement features from the training. \n",
    "* There are exist smart solutions which will be study on the next seminars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on sPlot data\n",
    "There are several ways how to train classifier on sPlot data:\n",
    "\n",
    "* Choose some threshold > 0 on weights and suppose that events with greater weights are signal and threshold < 0 to define background (this is in consistence with weights meaning).\n",
    "* As weights are linear combination of $p_s(y)$ and $p_b(y)$, one can put all events with $p_s(y)$ weight as signal and all events with $1 - p_s(y)$ as background.\n",
    "* apply bagging and select signal event from all events with $p_s(y)$ probability and backgroud events with $p_b(y)$ one.\n",
    "* apply bagging and and put 1-label with $p_s(y)$ probability and 0-labelwith $p_b(y)$.\n",
    "* maybe other ways\n",
    "\n",
    "**TODO**: \n",
    "\n",
    "* Try all listed ways compared them on the test dataset (`test_splot`). Test contains MC for $\\tau\\to 3\\mu$ and its sideband. On this data quality will be lower than it is actually is, because $\\tau\\to 3\\mu$ differs from $D_s\\to\\phi\\pi$\n",
    "* Can you suggest another way how to train classifier on sPlot data?\n",
    "\n",
    "**Note: the $p_s$ column is defined in the file `probabilities.csv` in folder `datasets`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_columns = list(set(data_agreement.columns) - {'weight'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splot_data = data_agreement[data_agreement.signal == 0]\n",
    "# probabilities to be signal events\n",
    "splot_probs = pandas.read_csv('datasets/probabilities.csv')['probs'].values\n",
    "test_splot = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot weights\n",
    "hist(splot_data.weight.values, **hist_kw)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose weight thresholds (say >1. for signal and  <-0.4 for bck)\n",
    "Remember that selected parts of data are not actually signal and bck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add events two times in training\n",
    "\n",
    "First time as signal with weight = probability_signal.\n",
    "\n",
    "Second time as background with weight = 1 - probability_signal. \n",
    "\n",
    "This method is equivalent to the following function optimization in logloss case for boosting:\n",
    "\n",
    "$\\mathbb{L} = \\sum_{y} p_s(y) * \\log{\\hat{p}(y)} + (1 - p_s(y)) * \\log{(1 - \\hat{p}(y))} =  \\sum_{y} label(y) * w(y) \\log{\\hat{p}(y)} +  (1 - label(y)) *  w(y)  \\log{(1 - \\hat{p}(y))}$, \n",
    "\n",
    "where $\\hat{p}$ is classifier's prediction and the right side is logloss in boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lirical thoughts: How this result can help to search for $\\tau\\to 3\\mu$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['new_feature'] = your_model.predict_proba(train[train_features])[:, 1]\n",
    "test['new_feature'] = your_model.predict_proba(test[train_features])[:, 1]\n",
    "data_agreement['new_feature'] = your_model.predict_proba(data_agreement[train_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_new = GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, min_samples_leaf=50, subsample=0.7, \n",
    "                                    max_features=20, max_depth=6)\n",
    "gb_new.fit(train[train_features_wo_spd + ['new_feature']], train['signal'].values)\n",
    "test_model(gb_new, train_features_wo_spd + ['new_feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with events sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn import clone\n",
    "# define sampler corresponding to probabilities (generate signal events using ifs pdf, the same for bck)\n",
    "class SampleSampler(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator, n_estimators=10, bootstrap=False, subsample=0.5):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.subsample = subsample\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # finish method: generate samples\n",
    "        if sample_weight is None:\n",
    "            sample_weight = numpy.ones(len(y))\n",
    "        y = numpy.array(y)\n",
    "        X = numpy.array(X)\n",
    "        \n",
    "        sig_size = ...\n",
    "        p_sig = sample_weight[y == 1]\n",
    "        p_sig /= p_sig.sum()\n",
    "        \n",
    "        bck_size = ...\n",
    "        p_bck = 1 - sample_weight[y == 0]\n",
    "        p_bck /= p_bck.sum()\n",
    "        self.estimators = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            base = clone(self.base_estimator)\n",
    "            used_samples = ...\n",
    "            base.fit(X[used_samples, :], y[used_samples], sample_weight=sample_weight[used_samples])\n",
    "            self.estimators.append(base)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        result = numpy.zeros([len(X), 2])\n",
    "        for clf in self.estimators:\n",
    "            result += clf.predict_proba(X)\n",
    "        return result / len(self.estimators)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return numpy.argmax(self.predict_proba(X), axis=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train SampleSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn import clone\n",
    "# define sampler corresponding to probabilities (generate labels for event using probabilities)\n",
    "class BaggingSampler(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator, n_estimators=10):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # finish method\n",
    "        if sample_weight is None:\n",
    "            sample_weight = numpy.ones(len(y))\n",
    "        y = numpy.array(y)\n",
    "        X = numpy.array(X)\n",
    "        # put for event label 1 with p_s probability and label 0 otherwise (sample_weight is p_s) \n",
    "        new_y = ...\n",
    "        self.estimators = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            ...\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        result = numpy.zeros([len(X), 2])\n",
    "        for clf in self.estimators:\n",
    "            result += clf.predict_proba(X)\n",
    "        return result / len(self.estimators)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return numpy.argmax(self.predict_proba(X), axis=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train BaggingSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize:\n",
    "\n",
    "* Different ways are possible to train classifier using probablity information from data.\n",
    "* Sometimes you need to train on sPlot data (take only singal) vs MC background. In this case you have two possibilities how to choose signal events\n",
    "    * make cut on sPlot weights (note, that only classifiers from TMVA library can use negative weights for events)\n",
    "    * choose events using sampling with signal probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
